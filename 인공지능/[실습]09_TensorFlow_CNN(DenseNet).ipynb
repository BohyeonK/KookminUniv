{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nG_X1BfzJwne"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'h5py.h5.H5PYConfig' has no attribute '__reduce_cython__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4997e47aaa06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence_feature_column\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# =============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetwork_serialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m   \u001b[1;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m   \u001b[0mh5py\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_version_tuple\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdf5_built_version_tuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\version.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_h5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\h5.pyx\u001b[0m in \u001b[0;36minit h5py.h5\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'h5py.h5.H5PYConfig' has no attribute '__reduce_cython__'"
     ]
    }
   ],
   "source": [
    "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "# pylint: disable=invalid-name\n",
    "\"\"\"DenseNet models for Keras.\n",
    "Reference:\n",
    "  - [Densely Connected Convolutional Networks](\n",
    "      https://arxiv.org/abs/1608.06993) (CVPR 2017)\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras.applications import imagenet_utils\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow.python.keras.layers import VersionAwareLayers\n",
    "from tensorflow.python.keras.utils import data_utils\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "\n",
    "\n",
    "BASE_WEIGTHS_PATH = ('https://storage.googleapis.com/tensorflow/'\n",
    "                     'keras-applications/densenet/')\n",
    "DENSENET121_WEIGHT_PATH = (\n",
    "    BASE_WEIGTHS_PATH + 'densenet121_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "DENSENET121_WEIGHT_PATH_NO_TOP = (\n",
    "    BASE_WEIGTHS_PATH +\n",
    "    'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "DENSENET169_WEIGHT_PATH = (\n",
    "    BASE_WEIGTHS_PATH + 'densenet169_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "DENSENET169_WEIGHT_PATH_NO_TOP = (\n",
    "    BASE_WEIGTHS_PATH +\n",
    "    'densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "DENSENET201_WEIGHT_PATH = (\n",
    "    BASE_WEIGTHS_PATH + 'densenet201_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "DENSENET201_WEIGHT_PATH_NO_TOP = (\n",
    "    BASE_WEIGTHS_PATH +\n",
    "    'densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "layers = VersionAwareLayers()\n",
    "\n",
    "\n",
    "def dense_block(x, blocks, name):\n",
    "    \"\"\"A dense block.\n",
    "  Arguments:\n",
    "    x: input tensor.\n",
    "    blocks: integer, the number of building blocks.\n",
    "    name: string, block label.\n",
    "  Returns:\n",
    "    Output tensor for the block.\n",
    "  \"\"\"\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    \"\"\"A transition block.\n",
    "  Arguments:\n",
    "    x: input tensor.\n",
    "    reduction: float, compression rate at transition layers.\n",
    "    name: string, block label.\n",
    "  Returns:\n",
    "    output tensor for the block.\n",
    "  \"\"\"\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis, epsilon=1.001e-5, name=name + '_bn')(\n",
    "          x)\n",
    "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "    x = layers.Conv2D(\n",
    "      int(backend.int_shape(x)[bn_axis] * reduction),\n",
    "      1,\n",
    "      use_bias=False,\n",
    "      name=name + '_conv')(\n",
    "          x)\n",
    "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(x, growth_rate, name):\n",
    "    \"\"\"A building block for a dense block.\n",
    "  Arguments:\n",
    "    x: input tensor.\n",
    "    growth_rate: float, growth rate at dense layers.\n",
    "    name: string, block label.\n",
    "  Returns:\n",
    "    Output tensor for the block.\n",
    "  \"\"\"\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    x1 = layers.BatchNormalization(\n",
    "      axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(\n",
    "          x)\n",
    "    x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "    x1 = layers.Conv2D(\n",
    "      4 * growth_rate, 1, use_bias=False, name=name + '_1_conv')(\n",
    "          x1)\n",
    "    x1 = layers.BatchNormalization(\n",
    "      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(\n",
    "          x1)\n",
    "    x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "    x1 = layers.Conv2D(\n",
    "      growth_rate, 3, padding='same', use_bias=False, name=name + '_2_conv')(\n",
    "          x1)\n",
    "    x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "    return x\n",
    "\n",
    "#DenseNet121일 경우,\n",
    "# DenseNet([6, 12, 24, 16], include_top, weights, input_tensor,\n",
    "#                   input_shape, pooling, classes)\n",
    "def DenseNet(\n",
    "    blocks, #[6, 12, 24, 16]\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'):\n",
    "    \"\"\"Instantiates the DenseNet architecture.\n",
    "  Reference:\n",
    "  - [Densely Connected Convolutional Networks](\n",
    "      https://arxiv.org/abs/1608.06993) (CVPR 2017)\n",
    "  Optionally loads weights pre-trained on ImageNet.\n",
    "  Note that the data format convention used by the model is\n",
    "  the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "  Note: each Keras Application expects a specific kind of input preprocessing.\n",
    "  For DenseNet, call `tf.keras.applications.densenet.preprocess_input` on your\n",
    "  inputs before passing them to the model.\n",
    "  Arguments:\n",
    "    blocks: numbers of building blocks for the four dense layers.\n",
    "    include_top: whether to include the fully-connected\n",
    "      layer at the top of the network.\n",
    "    weights: one of `None` (random initialization),\n",
    "      'imagenet' (pre-training on ImageNet),\n",
    "      or the path to the weights file to be loaded.\n",
    "    input_tensor: optional Keras tensor\n",
    "      (i.e. output of `layers.Input()`)\n",
    "      to use as image input for the model.\n",
    "    input_shape: optional shape tuple, only to be specified\n",
    "      if `include_top` is False (otherwise the input shape\n",
    "      has to be `(224, 224, 3)` (with `'channels_last'` data format)\n",
    "      or `(3, 224, 224)` (with `'channels_first'` data format).\n",
    "      It should have exactly 3 inputs channels,\n",
    "      and width and height should be no smaller than 32.\n",
    "      E.g. `(200, 200, 3)` would be one valid value.\n",
    "    pooling: optional pooling mode for feature extraction\n",
    "      when `include_top` is `False`.\n",
    "      - `None` means that the output of the model will be\n",
    "          the 4D tensor output of the\n",
    "          last convolutional block.\n",
    "      - `avg` means that global average pooling\n",
    "          will be applied to the output of the\n",
    "          last convolutional block, and thus\n",
    "          the output of the model will be a 2D tensor.\n",
    "      - `max` means that global max pooling will\n",
    "          be applied.\n",
    "    classes: optional number of classes to classify images\n",
    "      into, only to be specified if `include_top` is True, and\n",
    "      if no `weights` argument is specified.\n",
    "    classifier_activation: A `str` or callable. The activation function to use\n",
    "      on the \"top\" layer. Ignored unless `include_top=True`. Set\n",
    "      `classifier_activation=None` to return the logits of the \"top\" layer.\n",
    "  Returns:\n",
    "    A `keras.Model` instance.\n",
    "  Raises:\n",
    "    ValueError: in case of invalid argument for `weights`,\n",
    "      or invalid input shape.\n",
    "    ValueError: if `classifier_activation` is not `softmax` or `None` when\n",
    "      using a pretrained top layer.\n",
    "  \"\"\"\n",
    "    if not (weights in {'imagenet', None} or file_io.file_exists_v2(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                     '`None` (random initialization), `imagenet` '\n",
    "                     '(pre-training on ImageNet), '\n",
    "                     'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                     ' as true, `classes` should be 1000')\n",
    "\n",
    "  # Determine proper input shape\n",
    "    input_shape = imagenet_utils.obtain_input_shape(\n",
    "      input_shape,\n",
    "      default_size=224,\n",
    "      min_size=32,\n",
    "      data_format=backend.image_data_format(),\n",
    "      require_flatten=include_top,\n",
    "      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "#특징 추출 부분 시작 \n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n",
    "  #배치 정규화\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis, epsilon=1.001e-5, name='conv1/bn')(\n",
    "          x)\n",
    "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "\n",
    "  #densenet121일 경우, block내 denselayer 6개\n",
    "    x = dense_block(x, blocks[0], name='conv2')\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "  #densenet121일 경우, block내 denselayer 12개\n",
    "    x = dense_block(x, blocks[1], name='conv3')\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "  #densenet121일 경우, block내 denselayer 24개\n",
    "    x = dense_block(x, blocks[2], name='conv4')\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "  #densenet121일 경우, block내 denselayer 16개\n",
    "    x = dense_block(x, blocks[3], name='conv5')\n",
    "\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = layers.Activation('relu', name='relu')(x)\n",
    "\n",
    "  #분류 층 포함할 경우 \n",
    "    if include_top:\n",
    "    #Global Average Pooling layer\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "\n",
    "        imagenet_utils.validate_activation(classifier_activation, weights)\n",
    "    #클래스 개수에 맞게 최종 분류 \n",
    "        x = layers.Dense(classes, activation=classifier_activation,\n",
    "                     name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D(name='max_pool')(x)\n",
    "\n",
    "  # Ensure that the model takes into account\n",
    "  # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = layer_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "  #종류에 맞게 이름 설정 \n",
    "  # Create model.\n",
    "    if blocks == [6, 12, 24, 16]:\n",
    "        model = training.Model(inputs, x, name='densenet121')\n",
    "    elif blocks == [6, 12, 32, 32]:\n",
    "        model = training.Model(inputs, x, name='densenet169')\n",
    "    elif blocks == [6, 12, 48, 32]:\n",
    "        model = training.Model(inputs, x, name='densenet201')\n",
    "    else:\n",
    "        model = training.Model(inputs, x, name='densenet')\n",
    "\n",
    "  # Load weights.\n",
    "  #분류층 포함 여부에 따라서 가중치 로드 \n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            if blocks == [6, 12, 24, 16]:\n",
    "                weights_path = data_utils.get_file(\n",
    "            'densenet121_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "            DENSENET121_WEIGHT_PATH,\n",
    "            cache_subdir='models',\n",
    "            file_hash='9d60b8095a5708f2dcce2bca79d332c7')\n",
    "        elif blocks == [6, 12, 32, 32]:\n",
    "            weights_path = data_utils.get_file(\n",
    "            'densenet169_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "            DENSENET169_WEIGHT_PATH,\n",
    "            cache_subdir='models',\n",
    "            file_hash='d699b8f76981ab1b30698df4c175e90b')\n",
    "        elif blocks == [6, 12, 48, 32]:\n",
    "            weights_path = data_utils.get_file(\n",
    "            'densenet201_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "            DENSENET201_WEIGHT_PATH,\n",
    "            cache_subdir='models',\n",
    "            file_hash='1ceb130c1ea1b78c3bf6114dbdfd8807')\n",
    "        else:\n",
    "            if blocks == [6, 12, 24, 16]:\n",
    "                weights_path = data_utils.get_file(\n",
    "            'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "            DENSENET121_WEIGHT_PATH_NO_TOP,\n",
    "            cache_subdir='models',\n",
    "            file_hash='30ee3e1110167f948a6b9946edeeb738')\n",
    "            elif blocks == [6, 12, 32, 32]:\n",
    "                weights_path = data_utils.get_file(\n",
    "            'densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "            DENSENET169_WEIGHT_PATH_NO_TOP,\n",
    "            cache_subdir='models',\n",
    "            file_hash='b8c4d4c20dd625c148057b9ff1c1176b')\n",
    "            elif blocks == [6, 12, 48, 32]:\n",
    "                weights_path = data_utils.get_file(\n",
    "            'densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "            DENSENET201_WEIGHT_PATH_NO_TOP,\n",
    "            cache_subdir='models',\n",
    "            file_hash='c13680b51ded0fb44dff2d8f86ac8bb1')\n",
    "        model.load_weights(weights_path)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "#DenseNet 호출 시 종류에 따라 처음 호출되는 함수들 \n",
    "@keras_export('keras.applications.densenet.DenseNet121',\n",
    "              'keras.applications.DenseNet121')\n",
    "def DenseNet121(include_top=True,\n",
    "                weights='imagenet',\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    \"\"\"Instantiates the Densenet121 architecture.\"\"\"\n",
    "  #DenseNet 함수 호출 \n",
    "    return DenseNet([6, 12, 24, 16], include_top, weights, input_tensor,\n",
    "                  input_shape, pooling, classes)\n",
    "\n",
    "\n",
    "@keras_export('keras.applications.densenet.DenseNet169',\n",
    "              'keras.applications.DenseNet169')\n",
    "def DenseNet169(include_top=True,\n",
    "                weights='imagenet',\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    \"\"\"Instantiates the Densenet169 architecture.\"\"\"\n",
    "    return DenseNet([6, 12, 32, 32], include_top, weights, input_tensor,\n",
    "                  input_shape, pooling, classes)\n",
    "\n",
    "\n",
    "@keras_export('keras.applications.densenet.DenseNet201',\n",
    "              'keras.applications.DenseNet201')\n",
    "def DenseNet201(include_top=True,\n",
    "                weights='imagenet',\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "    \"\"\"Instantiates the Densenet201 architecture.\"\"\"\n",
    "    return DenseNet([6, 12, 48, 32], include_top, weights, input_tensor,\n",
    "                  input_shape, pooling, classes)\n",
    "\n",
    "\n",
    "@keras_export('keras.applications.densenet.preprocess_input')\n",
    "def preprocess_input(x, data_format=None):\n",
    "    return imagenet_utils.preprocess_input(\n",
    "      x, data_format=data_format, mode='torch')\n",
    "\n",
    "\n",
    "@keras_export('keras.applications.densenet.decode_predictions')\n",
    "def decode_predictions(preds, top=5):\n",
    "    return imagenet_utils.decode_predictions(preds, top=top)\n",
    "\n",
    "\n",
    "preprocess_input.__doc__ = imagenet_utils.PREPROCESS_INPUT_DOC.format(\n",
    "    mode='',\n",
    "    ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TORCH,\n",
    "    error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)\n",
    "decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n",
    "\n",
    "DOC = \"\"\"\n",
    "  Reference:\n",
    "  - [Densely Connected Convolutional Networks](\n",
    "      https://arxiv.org/abs/1608.06993) (CVPR 2017)\n",
    "  Optionally loads weights pre-trained on ImageNet.\n",
    "  Note that the data format convention used by the model is\n",
    "  the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "  Note: each Keras Application expects a specific kind of input preprocessing.\n",
    "  For DenseNet, call `tf.keras.applications.densenet.preprocess_input` on your\n",
    "  inputs before passing them to the model.\n",
    "  Arguments:\n",
    "    include_top: whether to include the fully-connected\n",
    "      layer at the top of the network.\n",
    "    weights: one of `None` (random initialization),\n",
    "      'imagenet' (pre-training on ImageNet),\n",
    "      or the path to the weights file to be loaded.\n",
    "    input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "      to use as image input for the model.\n",
    "    input_shape: optional shape tuple, only to be specified\n",
    "      if `include_top` is False (otherwise the input shape\n",
    "      has to be `(224, 224, 3)` (with `'channels_last'` data format)\n",
    "      or `(3, 224, 224)` (with `'channels_first'` data format).\n",
    "      It should have exactly 3 inputs channels,\n",
    "      and width and height should be no smaller than 32.\n",
    "      E.g. `(200, 200, 3)` would be one valid value.\n",
    "    pooling: Optional pooling mode for feature extraction\n",
    "      when `include_top` is `False`.\n",
    "      - `None` means that the output of the model will be\n",
    "          the 4D tensor output of the\n",
    "          last convolutional block.\n",
    "      - `avg` means that global average pooling\n",
    "          will be applied to the output of the\n",
    "          last convolutional block, and thus\n",
    "          the output of the model will be a 2D tensor.\n",
    "      - `max` means that global max pooling will\n",
    "          be applied.\n",
    "    classes: optional number of classes to classify images\n",
    "      into, only to be specified if `include_top` is True, and\n",
    "      if no `weights` argument is specified.\n",
    "  Returns:\n",
    "    A Keras model instance.\n",
    "\"\"\"\n",
    "\n",
    "setattr(DenseNet121, '__doc__', DenseNet121.__doc__ + DOC)\n",
    "setattr(DenseNet169, '__doc__', DenseNet169.__doc__ + DOC)\n",
    "setattr(DenseNet201, '__doc__', DenseNet201.__doc__ + DOC)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP8PJPbjyhvihlwWcMyvCUC",
   "collapsed_sections": [],
   "name": "DenseNet(Tensorflow).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
